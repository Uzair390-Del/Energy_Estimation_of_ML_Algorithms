{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree : 1st Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd Iteration: built in libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 8.31 seconds\n",
      "CPU Utilization: 12.1%\n",
      "Memory Usage: 62.5%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import psutil\n",
    "import time\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load MNIST data\n",
    "mnist = fetch_openml('mnist_784', as_frame=True)\n",
    "X, y = mnist.data.astype('float32').to_numpy(), mnist.target.astype('int')\n",
    "\n",
    "# Flatten the images\n",
    "X_flatten = np.array([image.flatten() for image in X])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_flatten, y, test_size=0.2, random_state=42)\n",
    "\n",
    "class CustomDecisionTree:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.model = DecisionTreeClassifier(max_depth=max_depth)\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Fit the scikit-learn decision tree model\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "        end_time = time.time()\n",
    "        training_time = end_time - start_time\n",
    "        print(f\"Training time: {training_time:.2f} seconds\")\n",
    "\n",
    "        # Monitor system status\n",
    "        cpu_percent = psutil.cpu_percent()\n",
    "        memory_percent = psutil.virtual_memory().percent\n",
    "        print(f\"CPU Utilization: {cpu_percent}%\")\n",
    "        print(f\"Memory Usage: {memory_percent}%\")\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        # Make predictions using the scikit-learn model\n",
    "        return self.model.predict(X_test)\n",
    "\n",
    "# Instantiate and fit the custom model\n",
    "dt_model = CustomDecisionTree(max_depth=10)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "#dt_predictions = dt_model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "#dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "#print(f\"Decision Tree Accuracy: {dt_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest: 1st iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall CPU Utilization: 15.1%\n",
      "Overall Memory Usage: 67.2%\n",
      "Time taken for training: 12.89 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "# Decision Tree class definition\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Decision tree training logic here\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Decision tree prediction logic here\n",
    "        pass\n",
    "\n",
    "# Random Forest class definition\n",
    "class RandomForest:\n",
    "    def __init__(self, n_estimators=100, max_depth=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.estimators = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for _ in range(self.n_estimators):\n",
    "            tree = DecisionTree(max_depth=self.max_depth)\n",
    "            X_sample, y_sample = self._bootstrap_sample(X, y)\n",
    "            tree.fit(X_sample, y_sample)\n",
    "            self.estimators.append(tree)\n",
    "\n",
    "    def _bootstrap_sample(self, X, y):\n",
    "        indices = np.random.choice(len(X), len(X), replace=True)\n",
    "        return X[indices], y.to_numpy()[indices]\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Random Forest prediction logic here\n",
    "        pass\n",
    "\n",
    "# Function to get CPU utilization and memory consumption\n",
    "def get_system_status():\n",
    "    cpu_percent = psutil.cpu_percent()\n",
    "    memory_percent = psutil.virtual_memory().percent\n",
    "    return cpu_percent, memory_percent\n",
    "\n",
    "# Load MNIST data\n",
    "mnist = fetch_openml('mnist_784', as_frame=True)\n",
    "df = pd.DataFrame(data=mnist.data.astype('float32'))\n",
    "X, y = df.to_numpy(), mnist.target.astype('int')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the features\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForest(n_estimators=100, max_depth=None)\n",
    "\n",
    "# Monitoring overall system status\n",
    "overall_cpu_utilization = []\n",
    "overall_memory_utilization = []\n",
    "\n",
    "# Training the Random Forest model\n",
    "start_time = time.time()\n",
    "\n",
    "# Reset the index of the DataFrame\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Monitor system status and log at the start\n",
    "cpu_percent, memory_percent = get_system_status()\n",
    "overall_cpu_utilization.append(cpu_percent)\n",
    "overall_memory_utilization.append(memory_percent)\n",
    "log_list = [{'Algorithm': 'Random Forest', 'CPU Utilization': cpu_percent, 'Memory Usage (%)': memory_percent, 'Training Time': 0.0}]\n",
    "\n",
    "# Calculate the time taken for training at the end\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "log_list[0]['Training Time'] = training_time\n",
    "\n",
    "# Print the overall CPU and memory utilization\n",
    "print(f\"Overall CPU Utilization: {np.mean(overall_cpu_utilization)}%\")\n",
    "print(f\"Overall Memory Usage: {np.mean(overall_memory_utilization)}%\")\n",
    "\n",
    "# Print the time taken for training\n",
    "print(f\"Time taken for training: {training_time:.2f} seconds\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "#rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "#rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "#print(f\"Random Forest Accuracy: {rf_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# second iteration: second method RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 38.48 seconds\n",
      "CPU Utilization: 16.2%\n",
      "Memory Usage: 69.6%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import psutil\n",
    "import time\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load MNIST data\n",
    "mnist = fetch_openml('mnist_784', as_frame=True)\n",
    "X, y = mnist.data.astype('float32').to_numpy(), mnist.target.astype('int')\n",
    "\n",
    "# Flatten the images\n",
    "X_flatten = np.array([image.flatten() for image in X])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_flatten, y, test_size=0.2, random_state=42)\n",
    "\n",
    "class CustomRandomForest:\n",
    "    def __init__(self, n_estimators=100, max_depth=None):\n",
    "        self.model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Fit the scikit-learn Random Forest model\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "        end_time = time.time()\n",
    "        training_time = end_time - start_time\n",
    "        print(f\"Training time: {training_time:.2f} seconds\")\n",
    "\n",
    "        # Monitor system status\n",
    "        cpu_percent = psutil.cpu_percent()\n",
    "        memory_percent = psutil.virtual_memory().percent\n",
    "        print(f\"CPU Utilization: {cpu_percent}%\")\n",
    "        print(f\"Memory Usage: {memory_percent}%\")\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        # Make predictions using the scikit-learn model\n",
    "        return self.model.predict(X_test)\n",
    "\n",
    "# Instantiate and fit the custom model\n",
    "rf_model = CustomRandomForest()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "#rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "#rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "#print(f\"Random Forest Accuracy: {rf_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM : 1st iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall CPU Utilization: 14.0%\n",
      "Overall Memory Usage: 58.5%\n",
      "Time taken for training: 199.57 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "# Function to get CPU utilization and memory consumption\n",
    "def get_system_status():\n",
    "    cpu_percent = psutil.cpu_percent()\n",
    "    memory_percent = psutil.virtual_memory().percent\n",
    "    return cpu_percent, memory_percent\n",
    "\n",
    "# Load MNIST data\n",
    "mnist = fetch_openml('mnist_784', as_frame=True)\n",
    "df = mnist.data.astype('float32')\n",
    "X, y = df.to_numpy(), mnist.target.astype('int')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm_model = SVC()\n",
    "\n",
    "# Monitoring overall system status\n",
    "overall_cpu_utilization = []\n",
    "overall_memory_utilization = []\n",
    "\n",
    "# Training the SVM model\n",
    "start_time = time.time()\n",
    "\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Monitor system status and log at the start\n",
    "cpu_percent, memory_percent = get_system_status()\n",
    "overall_cpu_utilization.append(cpu_percent)\n",
    "overall_memory_utilization.append(memory_percent)\n",
    "log_list = [{'Algorithm': 'SVM', 'CPU Utilization': cpu_percent, 'Memory Usage (%)': memory_percent, 'Training Time': 0.0}]\n",
    "\n",
    "# Calculate the time taken for training at the end\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "log_list[0]['Training Time'] = training_time\n",
    "\n",
    "# Print the overall CPU and memory utilization\n",
    "print(f\"Overall CPU Utilization: {np.mean(overall_cpu_utilization)}%\")\n",
    "print(f\"Overall Memory Usage: {np.mean(overall_memory_utilization)}%\")\n",
    "\n",
    "# Print the time taken for training\n",
    "print(f\"Time taken for training: {training_time:.2f} seconds\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "#svm_predictions = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "#svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "#print(f\"SVM Accuracy: {svm_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second iteration: Second Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 199.88 seconds\n",
      "CPU Utilization: 18.1%\n",
      "Memory Usage: 65.6%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import psutil\n",
    "import time\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load MNIST data\n",
    "mnist = fetch_openml('mnist_784', as_frame=True)\n",
    "X, y = mnist.data.astype('float32').to_numpy(), mnist.target.astype('int')\n",
    "\n",
    "# Flatten the images\n",
    "X_flatten = np.array([image.flatten() for image in X])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_flatten, y, test_size=0.2, random_state=42)\n",
    "\n",
    "class CustomSVM:\n",
    "    def __init__(self, kernel='rbf', C=1.0):\n",
    "        self.model = SVC(kernel=kernel, C=C)\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Fit the scikit-learn SVM model\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "        end_time = time.time()\n",
    "        training_time = end_time - start_time\n",
    "        print(f\"Training time: {training_time:.2f} seconds\")\n",
    "\n",
    "        # Monitor system status\n",
    "        cpu_percent = psutil.cpu_percent()\n",
    "        memory_percent = psutil.virtual_memory().percent\n",
    "        print(f\"CPU Utilization: {cpu_percent}%\")\n",
    "        print(f\"Memory Usage: {memory_percent}%\")\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        # Make predictions using the scikit-learn model\n",
    "        return self.model.predict(X_test)\n",
    "\n",
    "# Instantiate and fit the custom model\n",
    "svm_model = CustomSVM()\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "#svm_predictions = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "#svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "#print(f\"SVM Accuracy: {svm_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knn: 1st Iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall CPU Utilization: 16.8%\n",
      "Overall Memory Usage: 56.8%\n",
      "Time taken for training: 0.00 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "# KNN class definition\n",
    "class KNN:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        predictions = [self._predict(x) for x in X_test]\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def _predict(self, x):\n",
    "        distances = [np.linalg.norm(x - x_train) for x_train in self.X_train]\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "        most_common = np.bincount(k_nearest_labels).argmax()\n",
    "        return most_common\n",
    "\n",
    "# Function to get CPU utilization and memory consumption\n",
    "def get_system_status():\n",
    "    cpu_percent = psutil.cpu_percent()\n",
    "    memory_percent = psutil.virtual_memory().percent\n",
    "    return cpu_percent, memory_percent\n",
    "\n",
    "# Load MNIST data\n",
    "mnist = fetch_openml('mnist_784', as_frame=True)\n",
    "df = mnist.data.astype('float32')\n",
    "X, y = df.to_numpy(), mnist.target.astype('int')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the KNN model\n",
    "knn_model = KNN(k=3)\n",
    "\n",
    "# Monitoring overall system status\n",
    "overall_cpu_utilization = []\n",
    "overall_memory_utilization = []\n",
    "\n",
    "# Training the KNN model\n",
    "start_time = time.time()\n",
    "\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Monitor system status and log at the start\n",
    "cpu_percent, memory_percent = get_system_status()\n",
    "overall_cpu_utilization.append(cpu_percent)\n",
    "overall_memory_utilization.append(memory_percent)\n",
    "log_list = [{'Algorithm': 'k-NN', 'CPU Utilization': cpu_percent, 'Memory Usage (%)': memory_percent, 'Training Time': 0.0}]\n",
    "\n",
    "# Calculate the time taken for training at the end\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "log_list[0]['Training Time'] = training_time\n",
    "\n",
    "# Print the overall CPU and memory utilization\n",
    "print(f\"Overall CPU Utilization: {np.mean(overall_cpu_utilization)}%\")\n",
    "print(f\"Overall Memory Usage: {np.mean(overall_memory_utilization)}%\")\n",
    "\n",
    "# Print the time taken for training\n",
    "print(f\"Time taken for training: {training_time:.2f} seconds\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "#knn_predictions = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "#knn_accuracy = accuracy_score(y_test, knn_predictions)\n",
    "#print(f\"k-NN Accuracy: {knn_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Iteration: Second Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.04 seconds\n",
      "CPU Utilization: 13.4%\n",
      "Memory Usage: 63.1%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import psutil\n",
    "import time\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load MNIST data\n",
    "mnist = fetch_openml('mnist_784', as_frame=True)\n",
    "X, y = mnist.data.astype('float32').to_numpy(), mnist.target.astype('int')\n",
    "\n",
    "# Flatten the images\n",
    "X_flatten = np.array([image.flatten() for image in X])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_flatten, y, test_size=0.2, random_state=42)\n",
    "\n",
    "class CustomKNN:\n",
    "    def __init__(self, n_neighbors=3):\n",
    "        self.model = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Fit the scikit-learn KNN model\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "        end_time = time.time()\n",
    "        training_time = end_time - start_time\n",
    "        print(f\"Training time: {training_time:.2f} seconds\")\n",
    "\n",
    "        # Monitor system status\n",
    "        cpu_percent = psutil.cpu_percent()\n",
    "        memory_percent = psutil.virtual_memory().percent\n",
    "        print(f\"CPU Utilization: {cpu_percent}%\")\n",
    "        print(f\"Memory Usage: {memory_percent}%\")\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        # Make predictions using the scikit-learn model\n",
    "        return self.model.predict(X_test)\n",
    "\n",
    "# Instantiate and fit the custom model\n",
    "knn_model = CustomKNN()\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "#knn_predictions = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "#knn_accuracy = accuracy_score(y_test, knn_predictions)\n",
    "#print(f\"KNN Accuracy: {knn_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes: 1st Iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall CPU Utilization: 17.7%\n",
      "Overall Memory Usage: 61.2%\n",
      "Time taken for training: 2.52 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "# Naive Bayes class definition\n",
    "class NaiveBayes:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.classes, self.class_counts = np.unique(y_train, return_counts=True)\n",
    "        self.class_probs = self.class_counts / len(y_train)\n",
    "\n",
    "        # Convert NumPy array to Pandas DataFrame\n",
    "        df = pd.DataFrame(X_train)\n",
    "        df['target'] = y_train\n",
    "\n",
    "        self.mean = df.groupby('target').mean().to_numpy()\n",
    "        self.std = df.groupby('target').std().to_numpy()\n",
    "\n",
    "    def _calculate_likelihood(self, x, mean, std):\n",
    "        exponent = np.exp(-((x - mean) ** 2) / (2 * (std ** 2)))\n",
    "        return (1 / (np.sqrt(2 * np.pi) * std)) * exponent\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        predictions = []\n",
    "\n",
    "        for x in X_test:\n",
    "            class_probs = []\n",
    "\n",
    "            for i in range(len(self.classes)):\n",
    "                prior = np.log(self.class_probs[i])\n",
    "                likelihood = np.sum(np.log(self._calculate_likelihood(x, self.mean[i], self.std[i])))\n",
    "                posterior = prior + likelihood\n",
    "                class_probs.append(posterior)\n",
    "\n",
    "            predictions.append(self.classes[np.argmax(class_probs)])\n",
    "\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Function to get CPU utilization and memory consumption\n",
    "def get_system_status():\n",
    "    cpu_percent = psutil.cpu_percent()\n",
    "    memory_percent = psutil.virtual_memory().percent\n",
    "    return cpu_percent, memory_percent\n",
    "\n",
    "# Load MNIST data\n",
    "mnist = fetch_openml('mnist_784', as_frame=True)\n",
    "df = mnist.data.astype('float32')\n",
    "X, y = df.to_numpy(), mnist.target.astype('int')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the features\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "# Initialize the Naive Bayes model\n",
    "naive_bayes_model = NaiveBayes()\n",
    "\n",
    "# Monitoring overall system status\n",
    "overall_cpu_utilization = []\n",
    "overall_memory_utilization = []\n",
    "\n",
    "# Training the Naive Bayes model\n",
    "start_time = time.time()\n",
    "\n",
    "naive_bayes_model.fit(X_train, y_train)\n",
    "\n",
    "# Monitor system status and log at the start\n",
    "cpu_percent, memory_percent = get_system_status()\n",
    "overall_cpu_utilization.append(cpu_percent)\n",
    "overall_memory_utilization.append(memory_percent)\n",
    "log_list = [{'Algorithm': 'Naive Bayes', 'CPU Utilization': cpu_percent, 'Memory Usage (%)': memory_percent, 'Training Time': 0.0}]\n",
    "\n",
    "# Calculate the time taken for training at the end\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "log_list[0]['Training Time'] = training_time\n",
    "\n",
    "# Print the overall CPU and memory utilization\n",
    "print(f\"Overall CPU Utilization: {np.mean(overall_cpu_utilization)}%\")\n",
    "print(f\"Overall Memory Usage: {np.mean(overall_memory_utilization)}%\")\n",
    "\n",
    "# Print the time taken for training\n",
    "print(f\"Time taken for training: {training_time:.2f} seconds\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "#naive_bayes_predictions = naive_bayes_model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "#naive_bayes_accuracy = accuracy_score(y_test, naive_bayes_predictions)\n",
    "#print(f\"Naive Bayes Accuracy: {naive_bayes_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second iteration: Second method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.57 seconds\n",
      "CPU Utilization: 14.0%\n",
      "Memory Usage: 64.9%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import psutil\n",
    "import time\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load MNIST data\n",
    "mnist = fetch_openml('mnist_784', as_frame=True)\n",
    "X, y = mnist.data.astype('float32').to_numpy(), mnist.target.astype('int')\n",
    "\n",
    "# Flatten the images\n",
    "X_flatten = np.array([image.flatten() for image in X])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_flatten, y, test_size=0.2, random_state=42)\n",
    "\n",
    "class CustomNaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.model = GaussianNB()\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Fit the scikit-learn Naive Bayes model\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "        end_time = time.time()\n",
    "        training_time = end_time - start_time\n",
    "        print(f\"Training time: {training_time:.2f} seconds\")\n",
    "\n",
    "        # Monitor system status\n",
    "        cpu_percent = psutil.cpu_percent()\n",
    "        memory_percent = psutil.virtual_memory().percent\n",
    "        print(f\"CPU Utilization: {cpu_percent}%\")\n",
    "        print(f\"Memory Usage: {memory_percent}%\")\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        # Make predictions using the scikit-learn model\n",
    "        return self.model.predict(X_test)\n",
    "\n",
    "# Instantiate and fit the custom model\n",
    "nb_model = CustomNaiveBayes()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "#nb_predictions = nb_model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "#nb_accuracy = accuracy_score(y_test, nb_predictions)\n",
    "#print(f\"Naive Bayes Accuracy: {nb_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression: 1st Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall CPU Utilization: 24.2%\n",
      "Overall Memory Usage: 70.9%\n",
      "Time taken for training: 79.42 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "# Logistic Regression class definition\n",
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.theta = np.zeros(X_train.shape[1])\n",
    "\n",
    "        for _ in range(self.n_iterations):\n",
    "            z = np.dot(X_train, self.theta)\n",
    "            h = self.sigmoid(z)\n",
    "            gradient = np.dot(X_train.T, (h - y_train)) / y_train.size\n",
    "            self.theta -= self.learning_rate * gradient\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        z = np.dot(X_test, self.theta)\n",
    "        h = self.sigmoid(z)\n",
    "        return np.round(h)\n",
    "\n",
    "# Function to get CPU utilization and memory consumption\n",
    "def get_system_status():\n",
    "    cpu_percent = psutil.cpu_percent()\n",
    "    memory_percent = psutil.virtual_memory().percent\n",
    "    return cpu_percent, memory_percent\n",
    "\n",
    "# Load MNIST data\n",
    "mnist = fetch_openml('mnist_784', as_frame=True)\n",
    "df = mnist.data.astype('float32')\n",
    "X, y = df.to_numpy(), mnist.target.astype('int')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the features\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "# Add bias term to the features\n",
    "X_train = np.c_[np.ones((X_train.shape[0], 1)), X_train]\n",
    "X_test = np.c_[np.ones((X_test.shape[0], 1)), X_test]\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "logistic_regression_model = LogisticRegression(learning_rate=0.01, n_iterations=1000)\n",
    "\n",
    "# Monitoring overall system status\n",
    "overall_cpu_utilization = []\n",
    "overall_memory_utilization = []\n",
    "\n",
    "# Training the Logistic Regression model\n",
    "start_time = time.time()\n",
    "\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "# Monitor system status and log at the start\n",
    "cpu_percent, memory_percent = get_system_status()\n",
    "overall_cpu_utilization.append(cpu_percent)\n",
    "overall_memory_utilization.append(memory_percent)\n",
    "log_list = [{'Algorithm': 'Logistic Regression', 'CPU Utilization': cpu_percent, 'Memory Usage (%)': memory_percent, 'Training Time': 0.0}]\n",
    "\n",
    "# Calculate the time taken for training at the end\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "log_list[0]['Training Time'] = training_time\n",
    "\n",
    "# Print the overall CPU and memory utilization\n",
    "print(f\"Overall CPU Utilization: {np.mean(overall_cpu_utilization)}%\")\n",
    "print(f\"Overall Memory Usage: {np.mean(overall_memory_utilization)}%\")\n",
    "\n",
    "# Print the time taken for training\n",
    "print(f\"Time taken for training: {training_time:.2f} seconds\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "# logistic_regression_predictions = logistic_regression_model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "#logistic_regression_accuracy = accuracy_score(y_test, logistic_regression_predictions)\n",
    "#print(f\"Logistic Regression Accuracy: {logistic_regression_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd iteration: second method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 30.11 seconds\n",
      "CPU Utilization: 23.6%\n",
      "Memory Usage: 69.0%\n",
      "Logistic Regression Accuracy: 0.9178571428571428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PMLS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import psutil\n",
    "import time\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load MNIST data\n",
    "mnist = fetch_openml('mnist_784', as_frame=True)\n",
    "X, y = mnist.data.astype('float32').to_numpy(), mnist.target.astype('int')\n",
    "\n",
    "# Flatten the images\n",
    "X_flatten = np.array([image.flatten() for image in X])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_flatten, y, test_size=0.2, random_state=42)\n",
    "\n",
    "class CustomLogisticRegression:\n",
    "    def __init__(self):\n",
    "        self.model = LogisticRegression()\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Fit the scikit-learn logistic regression model\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "        end_time = time.time()\n",
    "        training_time = end_time - start_time\n",
    "        print(f\"Training time: {training_time:.2f} seconds\")\n",
    "\n",
    "        # Monitor system status\n",
    "        cpu_percent = psutil.cpu_percent()\n",
    "        memory_percent = psutil.virtual_memory().percent\n",
    "        print(f\"CPU Utilization: {cpu_percent}%\")\n",
    "        print(f\"Memory Usage: {memory_percent}%\")\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        # Make predictions using the scikit-learn model\n",
    "        return self.model.predict(X_test)\n",
    "\n",
    "# Instantiate and fit the custom model\n",
    "logreg_model = CustomLogisticRegression()\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "logreg_predictions = logreg_model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "logreg_accuracy = accuracy_score(y_test, logreg_predictions)\n",
    "print(f\"Logistic Regression Accuracy: {logreg_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
